{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tweets Impact Analysis with Natural Language Processing\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"_dataset/Mercadolibre_tweets.csv\")\n",
    "df[\"Max_Rt_Fav\"] = df[['favorite_count','retweet_count']].max(axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing and Tokens\n",
    "\n",
    "Here we clean the text column excluding rare characters (keeping only letters and numbers). Then we create a new column with the tokens of each text tweet. It means that we will descompose each sentence in a group of indenpendent words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text\"] = df[\"text\"].str.replace(\"[^0-9a-zA-Z ]+\",\" \")\n",
    "df[\"text\"] = df[\"text\"].str.lower()\n",
    "df[\"tokenized\"] = df[\"text\"].str.split()\n",
    "\n",
    "df = df.drop(['id', \"created_at\", \"favorite_count\", \"retweet_count\"], 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>Max_Rt_Fav</th>\n",
       "      <th>tokenized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>en 2020 incorporamos un promedio de 40 emplead...</td>\n",
       "      <td>1838</td>\n",
       "      <td>[en, 2020, incorporamos, un, promedio, de, 40,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>salvaje usa nuestra caja para dormir la siesta...</td>\n",
       "      <td>886</td>\n",
       "      <td>[salvaje, usa, nuestra, caja, para, dormir, la...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>d a a d a  m s de 80 mil pymes argentinas vend...</td>\n",
       "      <td>936</td>\n",
       "      <td>[d, a, a, d, a, m, s, de, 80, mil, pymes, arge...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sab as que m s de la mitad de las compras se ...</td>\n",
       "      <td>239</td>\n",
       "      <td>[sab, as, que, m, s, de, la, mitad, de, las, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>conoc  la historia de nouvelle factory  una py...</td>\n",
       "      <td>59</td>\n",
       "      <td>[conoc, la, historia, de, nouvelle, factory, u...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  Max_Rt_Fav  \\\n",
       "0  en 2020 incorporamos un promedio de 40 emplead...        1838   \n",
       "1  salvaje usa nuestra caja para dormir la siesta...         886   \n",
       "2  d a a d a  m s de 80 mil pymes argentinas vend...         936   \n",
       "3   sab as que m s de la mitad de las compras se ...         239   \n",
       "4  conoc  la historia de nouvelle factory  una py...          59   \n",
       "\n",
       "                                           tokenized  \n",
       "0  [en, 2020, incorporamos, un, promedio, de, 40,...  \n",
       "1  [salvaje, usa, nuestra, caja, para, dormir, la...  \n",
       "2  [d, a, a, d, a, m, s, de, 80, mil, pymes, arge...  \n",
       "3  [sab, as, que, m, s, de, la, mitad, de, las, c...  \n",
       "4  [conoc, la, historia, de, nouvelle, factory, u...  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we create a big matrix with all tokens, initialized with zeros. Later, it is probably that we will only be working with tokens that are more than X times repeated and under Y times repeated, to handle under/over fitting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_no_repeated = set()\n",
    "tokens_repeated = set()\n",
    "\n",
    "def clasify_tokens(vector):\n",
    "    for token in vector:\n",
    "        if token in tokens_no_repeated:\n",
    "            tokens_repeated.add(token)\n",
    "        else:\n",
    "            tokens_no_repeated.add(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens_analyzed = df[\"tokenized\"].apply(clasify_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hay 7555 tokens que no se repiten.\n",
      "Hay 2800 tokens que se repiten más de una vez.\n",
      "Solo un 37.06% de los tokens repetidos se repite más de una vez.\n"
     ]
    }
   ],
   "source": [
    "print(f\"Hay {len(tokens_no_repeated)} tokens que no se repiten.\")\n",
    "print(f\"Hay {len(tokens_repeated)} tokens que se repiten más de una vez.\")\n",
    "print(f\"Solo un {len(tokens_repeated)/(len(tokens_no_repeated))*100:.2f}% de los tokens repetidos se repite más de una vez.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = pd.DataFrame(0, index = np.arange(len(df[\"tokenized\"])),\n",
    "                      columns=tokens_repeated)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>jueves</th>\n",
       "      <th>colecci</th>\n",
       "      <th>tica</th>\n",
       "      <th>ocurrido</th>\n",
       "      <th>f</th>\n",
       "      <th>luisperezurra</th>\n",
       "      <th>lejos</th>\n",
       "      <th>mochila</th>\n",
       "      <th>tal</th>\n",
       "      <th>facebook</th>\n",
       "      <th>...</th>\n",
       "      <th>continua</th>\n",
       "      <th>play</th>\n",
       "      <th>obligatorio</th>\n",
       "      <th>a5ianksp</th>\n",
       "      <th>trayectoria</th>\n",
       "      <th>biles</th>\n",
       "      <th>cula</th>\n",
       "      <th>chat</th>\n",
       "      <th>mo</th>\n",
       "      <th>profesional</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 2800 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   jueves  colecci  tica  ocurrido  f  luisperezurra  lejos  mochila  tal  \\\n",
       "0       0        0     0         0  0              0      0        0    0   \n",
       "1       0        0     0         0  0              0      0        0    0   \n",
       "2       0        0     0         0  0              0      0        0    0   \n",
       "3       0        0     0         0  0              0      0        0    0   \n",
       "4       0        0     0         0  0              0      0        0    0   \n",
       "\n",
       "   facebook  ...  continua  play  obligatorio  a5ianksp  trayectoria  biles  \\\n",
       "0         0  ...         0     0            0         0            0      0   \n",
       "1         0  ...         0     0            0         0            0      0   \n",
       "2         0  ...         0     0            0         0            0      0   \n",
       "3         0  ...         0     0            0         0            0      0   \n",
       "4         0  ...         0     0            0         0            0      0   \n",
       "\n",
       "   cula  chat  mo  profesional  \n",
       "0     0     0   0            0  \n",
       "1     0     0   0            0  \n",
       "2     0     0   0            0  \n",
       "3     0     0   0            0  \n",
       "4     0     0   0            0  \n",
       "\n",
       "[5 rows x 2800 columns]"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we need to fill in each cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i, tokens in enumerate(df[\"tokenized\"]):\n",
    "    for token in tokens:\n",
    "        if token in tokens_repeated:\n",
    "            counts.loc[i,token] += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We keep only tokens between 5 and 100 counts."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_counts = counts.sum()\n",
    "counts = counts[word_counts[(word_counts <= 100) & (word_counts >= 5)].index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2717"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(counts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model\n",
    "\n",
    "#### **(Currently working on it)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#val = counts.iloc[2716]\n",
    "#counts = counts.iloc[0:2716]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(counts, df[\"Max_Rt_Fav\"], test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf = DecisionTreeClassifier()\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "predictions = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.9585826046939715\n",
      "Test score: 0.5588235294117647\n"
     ]
    }
   ],
   "source": [
    "print(\"Train score:\", clf.score(X_train, y_train)) #0.895\n",
    "print(\"Test score:\", clf.score(X_test, y_test)) #0.78 --> como acc,train>acc,test --> indicio de overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to train score is much higher than test score, there are signs of overfitting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf = DecisionTreeClassifier(max_depth=3)\n",
    "\n",
    "clf.fit(X_train, y_train)\n",
    "predictions = clf.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train score: 0.6148182236539347\n",
      "Test score: 0.6433823529411765\n"
     ]
    }
   ],
   "source": [
    "print(\"Train score:\", clf.score(X_train, y_train)) \n",
    "print(\"Test score:\", clf.score(X_test, y_test)) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! We can see that having fixed the tree max depth to 3, the model is less complex and dont overfit the data. Now, the test score is higher than train score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "452614.67463235295\n"
     ]
    }
   ],
   "source": [
    "mse = ((y_test - predictions)**2).sum()/len(predictions)\n",
    "print(mse)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_upvotes = df[\"Max_Rt_Fav\"].mean()\n",
    "std_upvotes = df[\"Max_Rt_Fav\"].std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean fav/rts: 82.79\n",
      "Standar deviation of fav/rts: 1824.09\n",
      "The root mean square error is: 672.77\n"
     ]
    }
   ],
   "source": [
    "print(\"Mean fav/rts: {:.2f}\".format(mean_upvotes))\n",
    "print(\"Standar deviation of fav/rts: {:.2f}\".format(std_upvotes))\n",
    "print(\"The root mean square error is: {:.2f}\".format(mse**0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the mean of the rts/favs is 82.79 and the standard deviation is 1824.09. If we take the square root of the MSE we see that it is 672.77, which can be interpreted as that our average error is 672.77 fav/rts away from the real value. This is a fairly high value, but this is fine for the purposes of this project. Must take into account that that we are dealing with a very small dataset, nor are we using transfer learning.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = clf.predict(counts.iloc[4:100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = counts.values.reshape((2717, 1009,1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DNN Model \n",
    "#### **(Currently working on it)**\n",
    "\n",
    "Using keras (from tensorflow) we train a neural network using LSTM architecture. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2173 samples, validate on 544 samples\n",
      "Epoch 1/5\n",
      "2173/2173 [==============================] - 35s 16ms/step - loss: 4054010.1743 - val_loss: 452609.1278\n",
      "Epoch 2/5\n",
      "2173/2173 [==============================] - 34s 16ms/step - loss: 4053837.3562 - val_loss: 452491.0454\n",
      "Epoch 3/5\n",
      "2173/2173 [==============================] - 35s 16ms/step - loss: 4053678.5676 - val_loss: 452452.9508\n",
      "Epoch 4/5\n",
      "2173/2173 [==============================] - 35s 16ms/step - loss: 4053622.2337 - val_loss: 452429.4108\n",
      "Epoch 5/5\n",
      "2173/2173 [==============================] - 35s 16ms/step - loss: 4053565.6387 - val_loss: 452407.5405\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Dense, Activation, LSTM\n",
    "from keras.models import Sequential\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.regularizers import l1\n",
    "\n",
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(counts, df[\"Max_Rt_Fav\"], test_size=0.2, random_state=1)\n",
    "\n",
    "hidden_layer = 16\n",
    "activation = \"relu\"\n",
    "input_layer = (1009)\n",
    "output_layer = 1\n",
    "epochs = 5\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(8, input_shape=(1009, 1)))\n",
    "model.add(Dense(1))\n",
    "\n",
    "model.compile(optimizer=\"adam\", loss=\"mean_squared_error\")\n",
    "\n",
    "history = model.fit(X_train, y_train, batch_size=16, epochs=epochs, validation_data=(X_test,y_test))\n",
    "\n",
    "y_pred = model.predict(X_test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
